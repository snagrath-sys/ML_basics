# -*- coding: utf-8 -*-
"""Univariate_linear_regression

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v65uf8lglBsdCZPc2CnHq_vGi7iqxh8S
"""

from google.colab import files
import io
import pandas as pd
import numpy as np
from mpl_toolkits import mplot3d 
import matplotlib.pyplot as plt 
import math

uploaded = files.upload()
uploaded2 = files.upload()

train_df= pd.read_csv(io.BytesIO(uploaded['Train_Univariate_linear_regression.csv']))
test_df= pd.read_csv(io.BytesIO(uploaded2['Test_univariate_linear_regression.csv']))

train_df.columns

train_df.plot('X','Y')

#Training

theta=[0,0]
theta0=0
theta1=0
step=0.01
m=len(train_df.index)
X=train_df[train_df.columns[0]]
Y=train_df[train_df.columns[1]]

def grad0(theta0, theta1,X,Y,m):
  #print("grad0")
  #print(sum(theta0+(theta1*X)-Y))
  return sum(theta0+(theta1*X)-Y)

def grad1(theta0,theta1,X,Y,m):
  #print("grad1")
  #print((sum((theta0+(theta1*X)-Y)*X)))
  return sum((theta0+(theta1*X)-Y)*X)

#Gradient descent
for i in range(100):
  print(i)
  dJtheta0=grad0(theta0,theta1,X,Y,m)
  dJtheta1=grad1(theta0,theta1,X,Y,m)
  theta0=theta0-(step*(1/m)*dJtheta0)
  theta1=theta1-(step*(1/m)*dJtheta1)
  cost=(1/2*m)*sum(np.square(theta0+(theta1*X)-Y))
  print(cost)

print("theta0",np.around(theta0,decimals=1))
print("theta1",theta1)

#Testing

X_test=test_df[test_df.columns[0]]
Y_test=test_df[test_df.columns[1]]

Y_predict=theta0+(theta1*X_test)

error=math.sqrt(sum(np.square(Y_predict-Y_test))/len(Y_test))

error

#Accuracy

Y_predict
Y_predict=np.around(Y_predict,decimals=1)

Y_test

cnt=0
for i in range(len(Y_test)):
  if(Y_predict[i]==Y_test[i]):
    cnt=cnt+1
    print(cnt)
accuracy=(cnt*100)/len(Y_test)

accuracy